

# 支持向量机

SVM有三宝：间隔，对偶，核技巧

从类别划分：硬间隔SVM（hard-margin SVM），软间隔(soft-margin SVM)，核方法(Kernel SVM)

### 1 硬间隔

![1](https://raorui.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC/06-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/1.png?Expires=1564285230&OSSAccessKeyId=TMP.hW45poxmzWmSmtratvCanPf34uoz8G7NT4thR6TggvVgYQVYYdwgGnJLTcfdVdG9LeV32xK1QsAhk2ZqcsqZZzkRDPaHvGV924zyuky6NpRt2ST2JaMYWZ6w1Gued5.tmp&Signature=DKk1IiCyzcI95agmfbQMBeYo2b8%3D)

$f(w)=\operatorname{sign}\left(w^{T} x+b\right)$ ：当$(w^{T} x+b)$ > 0时$f(w)=1$ 当$(w^{T} x+b)$ < 0时$f(w)=-1$  

#### 1.1 最大间隔分类器

$Data=\left\{\left(x_{i}, y_{i}\right)\right\}_{i=1}^{N}, \quad x_{i} \in \mathbb{R}^{p}, \quad y_{i} \in\{+1,-1\}$ 

**最大间隔**： $\max \operatorname{margin}(w, b)$ = $\min _{w, b, x_i,i=1..N} \operatorname{distance}\left(w, b, x_{i}\right)$ =$\min _{w, b,x_i} \frac{1}{\| w \|}\left|w^T x_{i}+b\right|$ 

**分类**：s.t. $\quad\left\{\begin{array}{l}{w^T x_{i}+b>0, y_{i}=+1} \\ {w^T x_{i}+b<0, y_{i}=-1}\end{array}\right.$ = s.t. $y_{i}\left(w^T x_{i}+b\right)>0$ , for $\forall i=1, \cdots, N$ 

可以得到：
$$
\left\{\begin{array}{l}
{\max _{w, b} \min _{x_{i}, i=1..N} \frac{1}{\|w\|}\left|w^T x_{i}+b\right|} \\
{\text { s.t. } y_{i}\left(w^T x_{i}+b\right)>0}
\end{array}\right.
$$
观察约束条件可以写成以下形式：
$$
\left\{\begin{array}{l}
{\max _{w, b} \min _{x_{i}, i=1..N} \frac{1}{\|w\|}y_i\left(w^T x_{i}+b\right)} =\max _{w, b} \frac{1}{\|w\|}\min _{x_{i}, i=1..N}y_i\left(w^T x_{i}+b\right) \\
{\text { s.t. } y_{i}\left(w^T x_{i}+b\right)>0}
\Rightarrow \exists r>0, \text { st } \min _{x_{i}} y_{i}\left(w^{T} x_{i}+b\right)=r
\end{array}\right.
$$
![2](https://raorui.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC/06-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/2.png?Expires=1564285279&OSSAccessKeyId=TMP.hW45poxmzWmSmtratvCanPf34uoz8G7NT4thR6TggvVgYQVYYdwgGnJLTcfdVdG9LeV32xK1QsAhk2ZqcsqZZzkRDPaHvGV924zyuky6NpRt2ST2JaMYWZ6w1Gued5.tmp&Signature=AoY2Yh3nm2FH9Z2zkaXM4P2eYp4%3D)

同时对$w$ 和$b$ 进行同比例缩放不影响超平面所以二者值有无穷多情况，让$\min _{x_{i}, i=1..N}y_i\left(w^T x_{i}+b\right) $ 用$r = 1$ 代替约束这无穷种情况
$$
\left\{\begin{array}{l}{\max _{w . b} \frac{1}{\|w\|}} \\ 
{\text { s.t } \min y_{i}\left(w^T x_{i}+b\right)=1}\end{array}\right.
$$
最优化的问题一般用最小表示，将第一个式子写成最小形式，将第二个式子写成不等式形式
$$
\left\{\begin{array}
{l}{\min _{w, b} \frac{1}{2} w^T w} \\ 
{\text { s.t. } y_{i}\left(w^T x_{i}+b\right) \geqslant 1}，for\forall i=1, \cdots, N\quad N个约束
\end{array}\right.
$$
此时将硬间隔的SVM变成了一个纯粹的优化问题即最小化问题，一个凸优化问题可以用软件解决



#### 1.2 对偶问题

当样本数和维度特别高时无法直接求解，可以借助拉拉格朗日乘法引出对偶问题

先写出他的**拉格朗日函数**：
$$
L(w, b, \lambda)=\frac{1}{2} w^T w+\sum_{i=1}^{N} \lambda_{i}\left(1-y_{i}\left(w^{T} x_{i}+b\right)\right)
$$
这种方法的限制$\lambda_{i}\geqslant0$ 且 $1-y_{i}\left(w^T x_{i}+b\right) \leq 0$    其中$\lambda=\left(\begin{array}{c}{\lambda_{1}} \\ {\lambda_{2}} \\ {\dot{\lambda}_{N}}\end{array}\right)$ 

##### 带约束问题

$Data=\left\{\left(x_{i}, y_{i}\right)\right\}_{i=1}^{N}, \quad x_{i} \in \mathbb{R}^{p}, \quad y_{i} \in\{+1,-1\}$
$$
\left\{\begin{array}
{l}{\min _{w, b} \frac{1}{2} w^{T} w} &\text{（1）}\\ 
{\text { s.t } y_{i}\left(w^T x_{i}+b\right) \geqslant 1 \Leftrightarrow 1-y_{i}\left(w^T x_{i}+b\right) \leqslant 0}
\end{array}\right.
$$

##### 无约束问题

(1)式为**带约束问题**，由拉格朗日函数得到**无约束问题**
$$
\left\{\begin{array}
{l}{\min _{w, b} \max _{\lambda}L(w, b, \lambda)} &\text{（2）}\\ 
{\text { s.t } \lambda_{i} \geqslant 0}
\end{array}\right.
$$

> 如果$1-y_{i}\left(w^T x_{i}+b\right)>0$ ，$\max _{\lambda}L(\lambda, w, b)=\frac{1}{2} w^{T} w+\infty=\infty$ 
>
> 如果$1-y_{i}\left(w^T x_{i}+b\right) \leq 0$ ，$\max _{\lambda}L(\lambda, w, b)=\frac{1}{2} w^{T} w+0=\frac{1}{2} w^{T} w$ $\min_{w,b}\max _{\lambda} f(w, b, \lambda)=\min _{w, b}\left(\infty, \frac{1}{2} w^T w\right)=\min _{w, b} \frac{1}{2} w^T w$ 
>
> 即通过对$\lambda$ 取最大，对$w,b$取最小，默认将$1-y_{i}\left(w^T x_{i}+b\right)>0$ 区域丢弃

##### 强对偶问题

(2)式的**对偶问题**(1,2式相等时为强对偶关系)
$$
\left\{\begin{array}
{l} \max _{\lambda}{\min _{w, b}L(w, b, \lambda)} &\text{（3）}\\ 
{\text { s.t } \lambda_{i} \geqslant 0}
\end{array}\right.
$$
+ 令$\frac{\partial L}{\partial b}=0$  得${\sum_{i=1}^{N} \lambda_{i} y_{i}}=0$ 

$$
\begin{array}
{l}\frac{\partial L}{\partial b}
=\frac{\partial}{\partial b}\left(\sum_{i=1}^{N} \lambda_{i}\left(1-y_{i}\left(w^{T} x_{i}+b\right)\right)\right.
{=\frac{\partial}{\partial b}\left(-\sum_{i=1}^{N} \lambda_{i} y_{i} b\right)} 
{=-\sum_{i=1}^{N} \lambda_{i} y_{i}}=0
\end{array}
$$
将${\sum_{i=1}^{N} \lambda_{i} y_{i}}=0$ 代入$L(w, b, \lambda)$  
$$
\begin{array}{l}
L(w, b, \lambda)
&=\frac{1}{2} w^{T} w+\sum_{i=1}^{N} \lambda_{i}-\sum_{i=1}^{N} \lambda_{i} y_{i}\left(w^{T} x_{i}+b\right) \\ 
&{=\frac{1}{2} w^{T} w+\sum_{i=1}^{N} \lambda_{i}-\sum_{i=1}^{N} \lambda_{i} y_{i} w^{T} x_{i}-\sum_{i=1}^{N} \lambda_{i} y_{i} b} \\
&{=\frac{1}{2} w^{T} w+\sum_{i=1}^{N} \lambda_{i}-\sum_{i=1}^{N} \lambda_{i} y_{i} w^{T} x_{i}} &\text{①}
\end{array}
$$
+ 令$\frac{\partial L}{\partial w}=0$ 得 $w=\sum_{i=1}^{N} \lambda_{i} y_{i} x_{i}$ 

$$
\frac{\partial L}{\partial w}=\frac{\partial}{\partial w} \frac{1}{2} w^{T} w+\frac{\partial}{\partial w} \sum_{i=1}^{N} \lambda_{i}\left(1-y_{i}\left(w^{T} x_{i}+b\right)\right)=\frac{1}{2} 2 w-\sum_{i=1}^{N} \lambda_{i} y_{i} x_{i}=0
$$
将$w=\sum_{i=1}^{N} \lambda_{i} y_{i} x_{i}$ 代入**①**          这里$x_i^Tx_j=x_j^Tx_i$ 
$$
\begin{array}{l}
L(w, b, \lambda)
&=\frac{1}{2} w^{T} w+\sum_{i=1}^{N} \lambda_{i}-\sum_{i=1}^{N} \lambda_{i} y_{i} w^{T} x_{i} \\ 
&{=\frac{1}{2}\left(\sum_{i=1}^{N} \lambda_{i} y_{i} x_{i}\right)^{T}\left(\sum_{j=1}^{N} \lambda_{j} y_{j} x_{j}\right)-\sum_{i=1}^{N} \lambda_{i} y_{i}\left(\sum_{j=1}^{N} \lambda_{j} y_{j} x_{j}\right)^{T} x_{i}+\sum_{i=1}^{N} \lambda_{i}} \\ 
&{=\frac{1}{2} \sum_{i=1}^{N} \lambda_{i} y_{i} x_{i}^{T} \sum_{j=1}^{N} \lambda_{j} y_{j} x_{j}-\sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} x_{i}^{T} x_{j}+\sum_{i=1}^{N} \lambda_{i}} \\ 
&{=-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} x_{i}^{T} x_{j}+\sum_{i=1}^{N} \lambda_{i}}\end{array}
$$
将结果代入(3)得到: 
$$
\left\{\begin{array}{l}{\max _{\lambda}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda_{j} y_{i} y_{j} x_{i}^T x_{j}+\sum_{i=1}^{N} \lambda_{i}} \\ {\text { s.t. } \lambda_{i} \geqslant 0}\qquad\sum_{i=1}^{N} \lambda_{i} y_{i}=0&\text{(4)}
\end{array}\right.
$$

#### 1.3 KKT条件

原问题, 对偶问题具有强对偶关系的充要条件是满足KKT条件
$$
\left\{\begin{array}{l}
{\frac{\partial L}{\partial w}=0 \quad \frac{\partial L}{\partial b}=0 \quad \frac{\partial L}{\partial \lambda}=0}&\text{梯度条件} \\ 
\lambda_{i}\left(1-y_{i}\left(w^T x_{i}+b\right)\right)=0&\text{松弛互补条件}\\
{\lambda_{i} \geqslant 0} \\
{1-y_{i}\left(w^{7} x_{i}+b\right) \leq 0}&\text{可行条件}
\end{array}\right.
$$
![3](https://raorui.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC/06-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/3.png?Expires=1564285320&OSSAccessKeyId=TMP.hW45poxmzWmSmtratvCanPf34uoz8G7NT4thR6TggvVgYQVYYdwgGnJLTcfdVdG9LeV32xK1QsAhk2ZqcsqZZzkRDPaHvGV924zyuky6NpRt2ST2JaMYWZ6w1Gued5.tmp&Signature=f%2BXRAH8qiWFqeHo4jWkgRfWQmMg%3D)

$w^T+b$ 超平面不在$w^T+b=1$这线上的$\lambda_i=0$  

由此条件可以求得$w^{*}=\sum_{i=0}^{N} \lambda_{i} y_{i} x_{i}$ (上式已求) $b^{*}$ 根据松弛互补条件求

> $w^{*}$ 是Data的线性组合

$\exists\left(x_{k}, y_{k}\right),$ s.t. $1-y_{k}\left(w^Tx_{k}+b\right)=0$ 

$b^{*}=y_{k}-w^{T} x_{k}=y_{k}-\sum_{i=0}^{n} \lambda_{i} y_{i} x_{i}^T x_{k}$ 
$$
w^{*}=\sum_{i=0}^{N} \lambda_{i} y_{i} x_{i} \qquad b^{*}=y_{k}-\sum_{i=0}^{N} \lambda_{i} y_{i} x_{i}^{T} x_{k}
$$
**决策函数**: $f(w)=\operatorname{sign}\left(w^{*T} x+b^*\right)$            **超平面**:$w^{*T} x+b^*$ 

### 2 软间隔

硬间隔在条件理想情况,软间格当有噪声时,允许一点错误
$$
{\min _{w, b} \frac{1}{2} w^T w} +loss
$$

+ $loss$ 为噪声点数(舍去)
$loss=\sum_{i=1}^{N} I\left\{y_{i}\left(w^{r} x_{i}+b\right)<1\right\}$  不连续

![4](https://raorui.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC/06-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/4.png?Expires=1564285302&OSSAccessKeyId=TMP.hW45poxmzWmSmtratvCanPf34uoz8G7NT4thR6TggvVgYQVYYdwgGnJLTcfdVdG9LeV32xK1QsAhk2ZqcsqZZzkRDPaHvGV924zyuky6NpRt2ST2JaMYWZ6w1Gued5.tmp&Signature=UFW4TdcJ%2FYroK%2BCEu2ZP6lfDkQw%3D)



+ $loss$ 为距离

如果$y_{i}\left(w^{T} x_{i}+b\right) \geqslant 1, \quad los s=0$

如果$y_{i}\left(w^{T} x_{i}+b\right)< 1,\quad los s=1-y_{i}\left(w^{T} x_{i}+b\right)$   


$$
loss =m a x\left\{0,1-y_{i}\left(w^Tx_{i}+b\right)\right\}
$$
![5](https://raorui.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC/06-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/5.png?Expires=1564285349&OSSAccessKeyId=TMP.hW45poxmzWmSmtratvCanPf34uoz8G7NT4thR6TggvVgYQVYYdwgGnJLTcfdVdG9LeV32xK1QsAhk2ZqcsqZZzkRDPaHvGV924zyuky6NpRt2ST2JaMYWZ6w1Gued5.tmp&Signature=hb1Sgt0kroesVtR%2FoCGpybiuddI%3D)
$$
\left\{\begin{array}{l}{\min _{w ,b} \frac{1}{2} w^{T} w+C \sum_{i=1}^{N} \max \left\{0,1-y_{i}\left(w^T x_{i}+b\right)\right\}} \\ {\text { s.t. } y_{i}\left(w^T x_{i}+b\right) \geqslant 1}\end{array}\right.
$$
引入$ξ_i=1-y_{i}\left(w^{T} x_{i}+b\right),ξ_i\geqslant0$ 

![6](https://raorui.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC/06-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/6.png?Expires=1564285362&OSSAccessKeyId=TMP.hW45poxmzWmSmtratvCanPf34uoz8G7NT4thR6TggvVgYQVYYdwgGnJLTcfdVdG9LeV32xK1QsAhk2ZqcsqZZzkRDPaHvGV924zyuky6NpRt2ST2JaMYWZ6w1Gued5.tmp&Signature=zTr1AMG88YyGo3svoa27%2BlNF8HQ%3D)

$$
\left\{\begin{array}{l}
\min _{w ,b} \frac{1}{2} w^{T} w+c \sum_{i=1}^{N} \xi_{i}
\\ 
{\text { s.t. } y_{i}\left(w^T x_{i}+b\right) \geqslant 1-ξ_i,ξ_i\geqslant0}
\end{array}\right.
$$


### 3 约束优化问题